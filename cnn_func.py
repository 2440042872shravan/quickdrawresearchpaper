# -*- coding: utf-8 -*-
"""cnn_func.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nhOFYdOykNBrh7NUbqBkJ_81FiRnjRxC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
np.random.seed(32113)

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers.convolutional import ZeroPadding2D
from keras.utils import np_utils
from keras.models import load_model


def Recognize_CNN_image_dataset(df1,df2,df3,df4, sample=30000,binary=False,\
                        convlayer =64,neuron =100, batchsize =500, epoch =10):
    Xtemp1, labeldump = Recognize_CNN_image_dataset(df1,df2,sample=sample)
    xtemp2, labeldump = Recognize_CNN_image_dataset(df3,df4,sample=sample)
    label = sample*[0]+sample*[1]+sample*[2]+sample*[3]
    label = pd.Series(label)
    X = pd.concat([Xtemp1,xtemp2],axis = 0)
    # runs CNN_model_builder with X and label. returns CNN model and X,Y train and test dataset
    return CNN_model_builder(X,label,binary=binary,category = 4,\
                            cnnp =[convlayer,neuron], fitp =[batchsize,epoch])
    def predict_country_using_cnn(df1,df2,df3,df4,sample=30000,limit=5000,
                                binary=False, convlayer =64,neuron =100, \
                                            batchsize =500, epoch =10):
      X,label = cc_prediction_datasetup(df1,df2,df3,df4, \
                                countries = ['US','BR','RU','KR'], limit = limit)
    label = pd.Series(label)
  
    return CNN_model_builder(X,label,binary=binary,category = 4,\
                            cnnp =[convlayer,neuron], fitp =[batchsize,epoch])
def datasetup_image_recognition(df1,df2,df3,df4,sample=30000):
    random_index1 = np.random.choice(list(df1.index), sample, replace=False)
    random_index2 = np.random.choice(list(df2.index), sample, replace=False)
    df1 = df1.loc[list(random_index1)]
    df2 = df2.loc[list(random_index2)]

    df_test = pd.concat([df1,df2],axis = 0)
    df_test = df_test.drop(['countrycode','word'], axis=1)
    label = [1]*sample+[0]*sample
    # 1= df1, 0 = df2
    label = np.array(label)
    label = pd.Series(label)
    label.index = df_test.index
    return df_test,label
def CNN_model_builder(X,label,binary=False, category =4, cnnp =[64,100], fitp =[500,10]):
   # when binary is True, the image is represented with 0 and 1.
    # meaning that non-zero values are replaced with 1.
    if binary:
        X = np.array(X)
        X[X != 0.0] = 1
        data_np = X
    # when binary is False, images contains time values as a 3rd dimension value.
    # the time values (in sec) is normalized 
    else:
        data_np = np.array(X)
        #normalizing time values
        data_np /= 10000
        data_np += 1
        data_np[data_np == 1.0] = 0

    label2 = np_utils.to_categorical(label, category)
    data_np = data_np.reshape(len(data_np),42,28,1)

    #train,test split
    X_train,X_test,y_train,y_test =train_test_split(data_np,label2,test_size = 0.15, \
                                                    random_state=831713, stratify = label2)
    # KERAS model (explained above)
    model = Sequential()
    model.add(Convolution2D(cnnp[0], 5, 5, activation='relu', input_shape=(42,28,1)))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(cnnp[1], activation='relu'))
    model.add(Dropout(.20))
    model.add(Dense(category, activation='softmax'))

    model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['accuracy'])
    #once model is created, it will be fitted with training datasets
    model.fit(X_train, y_train,
          batch_size=fitp[0], nb_epoch=fitp[1], verbose=1,validation_split=0.2)

    #score = model.evaluate(X_test, y_test,  batch_size=100)
    return model,X_train,y_train,X_test,y_test


def cc_prediction_datasetup(df1,df2,df3,df4, countries = ['US','BR','RU','KR'],\
                                                            limit = 5000):

    df = pd.concat([df1,df2,df3,df4], axis=0)

    # US
    df_US = _country_initial_fixer(df,countries[0],limit)
    #BR
    df_BR = _country_initial_fixer(df,countries[1],limit)
    #RU
    df_RU = _country_initial_fixer(df,countries[2],limit)
    #KR
    df_KR = _country_initial_fixer(df,countries[3],limit)

    print(len(df_US))
    print(len(df_BR))
    print(len(df_RU))
    print(len(df_KR))

    new_df = pd.concat([df_US,df_BR,df_RU,df_KR], axis=0)
    Y = new_df.pop('countrycode')
    new_df = new_df.drop(['word'], axis=1)
    b_loon = {}
    for i in range(len(countries)):
        b_loon[countries[i]] = i
    Y = Y.map(b_loon)

    return new_df,Y


def _country_initial_fixer(df,country,limit):
    if df[df['countrycode']==country].count()[0] > limit:
        df_c = df[df['countrycode']==country]
        random_c = np.random.choice(list(df_c.index), limit, replace=False)
        df_c = df_c.loc[list(random_c)]
    else:
        df_c = df[df['countrycode']==country]
    return df_c